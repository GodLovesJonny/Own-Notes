one-hot encoding result is independent  

  
"You shall know a word by the company it keeps."(J. R. Firth)    
"distributional similarity"    

## word2vec
### distributed representations of words
define a model that aims to predict between a center wt and context words in terms of word vectors  

	p(context|Wt)  

which has a loss function, e.g.,   
	    
	J = 1-p(W-t|Wt)   

W-t means words in Wt's context    
keep adjusting the vector representations of words to minimize the loss
